"Case 1: Dr. Farah Tan (Malay, Humanities Department – Sociology of Technology)"

Dr. Tan uses ChatGPT in a discussion-based seminar to help students analyze social implications of AI. Students were asked to simulate arguments on surveillance ethics using GPT-generated content.
Issue: She later discovers students inputted private family narratives from interview assignments into ChatGPT. This raises cultural sensitivity concerns and breaches of informed consent.
"Response: Dr. Tan pauses the use of AI and creates a workshop on digital ethics, emphasizing data ownership, oral traditions, and cultural respect, incorporating values from the Malay community about safeguarding family stories."



"Case 2: Prof. Rajiv Kumar (Indian, Engineering Department – AI Systems Design)"

Prof. Kumar introduces GitHub Copilot and ChatGPT to assist in code generation and documentation. He notices that students frequently submit polished assignments without understanding the logic behind them.
"Issue: A team uploads confidential FYP system architecture to ChatGPT for bug fixes, violating the university’s IP policy."
"Response: Prof. Kumar initiates a seminar on technical plagiarism, IP rights, and AI over-reliance. He redefines assessment by including oral code walkthroughs to test understanding. He also develops a clear disclosure form for students declaring AI tool use in their submissions."



"Case 3: Dr. Grace Lim (Chinese, Science Faculty – Environmental Biology)"

Dr. Lim incorporates AI tools for assisting students in scientific report writing. She uses GPT to generate summaries of lab results.
"Issue: During peer review, students flag that AI-generated summaries contain factual inaccuracies and fabricated data interpretations, which some students didn’t verify before submission."
"Response: Dr. Lim halts AI use temporarily and guides students through a lab session on critical evaluation of AI-generated content, emphasizing scientific reliability and the importance of human reasoning. She co-develops an “AI Use Protocol” with her class, balancing creativity with rigor."


Learning Process Analysis Points

1. Literature Search Selection:
"Students are guided to explore peer-reviewed journals (e.g., AI & Society, Ethics and Information Technology) and institutional reports (e.g., UNESCO, EDUCAUSE) to gather diverse perspectives on AI in education."

2. Critical Evaluation of Sources:
"Students evaluate the credibility of each source, assessing authorship, evidence of bias, empirical backing, and relevance to educational ethics."

3. Synthesizing Research Insights:
"Findings are synthesized across domains (privacy, pedagogy, misinformation, data ownership), connecting technical risks to humanistic values in education."

4. Identifying Research Gaps:
Students note a lack of empirical research on student perspectives about data sharing with AI tools and propose mini-projects to explore these gaps.



Three Key Questions

1. How can educators ensure student data remains private and secure when using external AI tools in coursework?

"2. To what extent does AI-assisted learning affect students’ sense of authorship, creativity, and academic integrity?"

3. How can we balance the pedagogical advantages of AI with the need to preserve authentic teacher-student relationships?